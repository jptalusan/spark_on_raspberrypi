{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# spark_home = os.environ.get('SPARK_HOME', None)\n",
    "# if not spark_home:\n",
    "#     raise ValueError('SPARK_HOME environment variable is not set')\n",
    "# sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "# sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.4-src.zip'))\n",
    "# exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x70d8c930>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import numpy\n",
    "\n",
    "import atexit\n",
    "from time import time, strftime, localtime\n",
    "from datetime import timedelta\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setAppName('My Jupyter Notebook')\n",
    "conf.set(\"spark.cores.max\", \"16\")\n",
    "if 'sc' in locals():\n",
    "    sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "conf.set(\"spark.yarn.executor.memoryOverhead\", \"0\")\n",
    "conf.set(\"spark.yarn.executor.memory\", \"512M\")\n",
    "conf.set(\"spark.yarn.driver.memory\", \"512M\")\n",
    "\n",
    "conf.set(\"spark.submit.deployMode\", \"client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secondsToStr(elapsed=None):\n",
    "    if elapsed is None:\n",
    "        return strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n",
    "    else:\n",
    "        return str(timedelta(seconds=elapsed))\n",
    "\n",
    "def log(s, elapsed=None):\n",
    "    line = \"=\"*40\n",
    "    print(line)\n",
    "    print(secondsToStr(), '-', s)\n",
    "    if elapsed:\n",
    "        print(\"Elapsed time:\", elapsed)\n",
    "    print(line)\n",
    "    print()\n",
    "\n",
    "def endlog():\n",
    "    end = time()\n",
    "    elapsed = end-start\n",
    "#     print(\"Elapsed time 2: \", elapsed)\n",
    "    log(\"End Program\", secondsToStr(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestMLib(cores):\n",
    "    start = time()\n",
    "#     atexit.register(endlog)\n",
    "    log(\"Start program: \" + str(cores))\n",
    "    \n",
    "    data = MLUtils.loadLibSVMFile(sc, \"/house_data\")\n",
    "    (trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    model = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)\n",
    "    \n",
    "    predictions = model.predict(testData.map(lambda x: x.features))\n",
    "    labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "    \n",
    "    testErr = labelsAndPredictions.filter(\n",
    "        lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "    \n",
    "    print('Test Error = ' + str(testErr))\n",
    "    print('Learned classification forest model:')\n",
    "    print(model.toDebugString())\n",
    "    end = time()\n",
    "    elapsed = end - start\n",
    "    print(\"End program \" + str(cores) + \": \" + str(secondsToStr(elapsed)))\n",
    "#     endlog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "2018-02-28 18:39:03 - Start program: 2\n",
      "========================================\n",
      "\n",
      "Test Error = 0.06451612903225806\n",
      "Learned classification forest model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 378 <= 36.0)\n",
      "     If (feature 214 <= 253.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 214 > 253.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 378 > 36.0)\n",
      "     Predict: 1.0\n",
      "  Tree 1:\n",
      "    If (feature 378 <= 0.0)\n",
      "     If (feature 380 <= 0.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 380 > 0.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 378 > 0.0)\n",
      "     If (feature 549 <= 251.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 549 > 251.0)\n",
      "      If (feature 380 <= 0.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 380 > 0.0)\n",
      "       Predict: 1.0\n",
      "  Tree 2:\n",
      "    If (feature 262 <= 0.0)\n",
      "     If (feature 407 <= 0.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 407 > 0.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 262 > 0.0)\n",
      "     If (feature 176 <= 208.0)\n",
      "      If (feature 462 <= 0.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 462 > 0.0)\n",
      "       Predict: 1.0\n",
      "     Else (feature 176 > 208.0)\n",
      "      Predict: 1.0\n",
      "\n",
      "End program 2: 0:00:55.875240\n"
     ]
    }
   ],
   "source": [
    "randomForestMLib(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark Python 3",
   "language": "python3",
   "name": "pyspark-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
